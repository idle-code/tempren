# Generated from TagTemplateLexer.g4 by ANTLR 4.8
import sys
from io import StringIO
from typing.io import TextIO

from antlr4 import *


def serializedATN():
    with StringIO() as buf:
        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2\26")
        buf.write("\u009a\b\1\b\1\b\1\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5")
        buf.write("\4\6\t\6\4\7\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f")
        buf.write("\t\f\4\r\t\r\4\16\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4")
        buf.write("\22\t\22\4\23\t\23\4\24\t\24\4\25\t\25\4\26\t\26\4\27")
        buf.write("\t\27\4\30\t\30\3\2\3\2\5\2\67\n\2\3\2\3\2\3\2\7\2<\n")
        buf.write("\2\f\2\16\2?\13\2\3\3\3\3\3\4\3\4\3\5\3\5\3\5\3\5\3\6")
        buf.write("\3\6\3\6\3\6\3\6\3\7\3\7\3\b\3\b\3\t\6\tS\n\t\r\t\16\t")
        buf.write("T\3\n\3\n\3\13\3\13\3\13\3\13\3\f\3\f\3\f\3\f\3\f\3\r")
        buf.write("\3\r\3\16\3\16\3\16\3\16\3\17\3\17\3\17\3\17\3\17\3\20")
        buf.write("\3\20\3\20\3\20\3\21\6\21r\n\21\r\21\16\21s\3\22\3\22")
        buf.write("\3\22\3\22\3\22\3\22\3\22\3\22\3\22\5\22\177\n\22\3\23")
        buf.write("\3\23\3\23\3\23\3\23\3\24\3\24\3\24\3\24\3\24\3\25\3\25")
        buf.write("\3\26\3\26\3\27\3\27\3\27\6\27\u0092\n\27\r\27\16\27\u0093")
        buf.write("\3\30\3\30\3\30\3\30\3\30\2\2\31\6\2\b\2\n\2\f\3\16\4")
        buf.write('\20\5\22\6\24\7\26\b\30\t\32\n\34\13\36\f \r"\16$\17')
        buf.write("&\20(\26*\21,\22.\23\60\24\62\25\6\2\3\4\5\b\4\2C\\c|")
        buf.write("\3\2\62;\4\2\13\f\17\17\7\2\13\f\17\17''}}\177\177\5")
        buf.write('\2\13\f\17\17""\4\2))^^\2\u009c\2\f\3\2\2\2\2\16\3\2')
        buf.write("\2\2\2\20\3\2\2\2\2\22\3\2\2\2\2\24\3\2\2\2\2\26\3\2\2")
        buf.write("\2\3\30\3\2\2\2\3\32\3\2\2\2\3\34\3\2\2\2\4\36\3\2\2\2")
        buf.write('\4 \3\2\2\2\4"\3\2\2\2\4$\3\2\2\2\4&\3\2\2\2\4(\3\2\2')
        buf.write("\2\4*\3\2\2\2\4,\3\2\2\2\4.\3\2\2\2\5\60\3\2\2\2\5\62")
        buf.write("\3\2\2\2\6\66\3\2\2\2\b@\3\2\2\2\nB\3\2\2\2\fD\3\2\2\2")
        buf.write("\16H\3\2\2\2\20M\3\2\2\2\22O\3\2\2\2\24R\3\2\2\2\26V\3")
        buf.write("\2\2\2\30X\3\2\2\2\32\\\3\2\2\2\34a\3\2\2\2\36c\3\2\2")
        buf.write('\2 g\3\2\2\2"l\3\2\2\2$q\3\2\2\2&~\3\2\2\2(\u0080\3\2')
        buf.write("\2\2*\u0085\3\2\2\2,\u008a\3\2\2\2.\u008c\3\2\2\2\60\u0091")
        buf.write("\3\2\2\2\62\u0095\3\2\2\2\64\67\5\b\3\2\65\67\7a\2\2\66")
        buf.write("\64\3\2\2\2\66\65\3\2\2\2\67=\3\2\2\28<\5\b\3\29<\5\n")
        buf.write("\4\2:<\7a\2\2;8\3\2\2\2;9\3\2\2\2;:\3\2\2\2<?\3\2\2\2")
        buf.write("=;\3\2\2\2=>\3\2\2\2>\7\3\2\2\2?=\3\2\2\2@A\t\2\2\2A\t")
        buf.write("\3\2\2\2BC\t\3\2\2C\13\3\2\2\2DE\t\4\2\2EF\3\2\2\2FG\b")
        buf.write("\5\2\2G\r\3\2\2\2HI\7'\2\2IJ\3\2\2\2JK\b\6\2\2KL\b\6")
        buf.write("\3\2L\17\3\2\2\2MN\7}\2\2N\21\3\2\2\2OP\7\177\2\2P\23")
        buf.write("\3\2\2\2QS\n\5\2\2RQ\3\2\2\2ST\3\2\2\2TR\3\2\2\2TU\3\2")
        buf.write("\2\2U\25\3\2\2\2VW\13\2\2\2W\27\3\2\2\2XY\t\4\2\2YZ\3")
        buf.write("\2\2\2Z[\b\13\2\2[\31\3\2\2\2\\]\7*\2\2]^\3\2\2\2^_\b")
        buf.write("\f\2\2_`\b\f\4\2`\33\3\2\2\2ab\5\6\2\2b\35\3\2\2\2cd\t")
        buf.write("\6\2\2de\3\2\2\2ef\b\16\2\2f\37\3\2\2\2gh\7+\2\2hi\3\2")
        buf.write("\2\2ij\b\17\2\2jk\b\17\5\2k!\3\2\2\2lm\7.\2\2mn\3\2\2")
        buf.write("\2no\b\20\2\2o#\3\2\2\2pr\5\n\4\2qp\3\2\2\2rs\3\2\2\2")
        buf.write("sq\3\2\2\2st\3\2\2\2t%\3\2\2\2uv\7v\2\2vw\7t\2\2wx\7w")
        buf.write("\2\2x\177\7g\2\2yz\7h\2\2z{\7c\2\2{|\7n\2\2|}\7u\2\2}")
        buf.write("\177\7g\2\2~u\3\2\2\2~y\3\2\2\2\177'\3\2\2\2\u0080\u0081")
        buf.write("\7)\2\2\u0081\u0082\7)\2\2\u0082\u0083\3\2\2\2\u0083\u0084")
        buf.write("\b\23\6\2\u0084)\3\2\2\2\u0085\u0086\7)\2\2\u0086\u0087")
        buf.write("\3\2\2\2\u0087\u0088\b\24\2\2\u0088\u0089\b\24\7\2\u0089")
        buf.write("+\3\2\2\2\u008a\u008b\5\6\2\2\u008b-\3\2\2\2\u008c\u008d")
        buf.write("\7?\2\2\u008d/\3\2\2\2\u008e\u0092\n\7\2\2\u008f\u0090")
        buf.write("\7^\2\2\u0090\u0092\t\7\2\2\u0091\u008e\3\2\2\2\u0091")
        buf.write("\u008f\3\2\2\2\u0092\u0093\3\2\2\2\u0093\u0091\3\2\2\2")
        buf.write("\u0093\u0094\3\2\2\2\u0094\61\3\2\2\2\u0095\u0096\7)\2")
        buf.write("\2\u0096\u0097\3\2\2\2\u0097\u0098\b\30\2\2\u0098\u0099")
        buf.write("\b\30\b\2\u0099\63\3\2\2\2\16\2\3\4\5\66;=Ts~\u0091\u0093")
        buf.write("\t\b\2\2\7\3\2\7\4\2\4\2\2\t\24\2\7\5\2\6\2\2")
        return buf.getvalue()


class TagTemplateLexer(Lexer):

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [DFA(ds, i) for i, ds in enumerate(atn.decisionToState)]

    TAG_MODE = 1
    ARGS_MODE = 2
    STRING_MODE = 3

    GLOBAL_WHITESPACE = 1
    TAG_START = 2
    CONTEXT_START = 3
    CONTEXT_END = 4
    TEXT = 5
    ANY = 6
    TAG_WHITESPACE = 7
    ARGS_START = 8
    TAG_ID = 9
    ARGS_WHITESPACE = 10
    ARG_END = 11
    ARG_SEPARATOR = 12
    NUMERIC_VALUE = 13
    BOOLEAN_VALUE = 14
    STRING_START = 15
    ARG_NAME = 16
    ARG_EQUALS = 17
    STRING_VALUE = 18
    STRING_END = 19
    EMPTY_STRING = 20

    channelNames = [u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN"]

    modeNames = ["DEFAULT_MODE", "TAG_MODE", "ARGS_MODE", "STRING_MODE"]

    literalNames = [
        "<INVALID>",
        "'%'",
        "'{'",
        "'}'",
        "'('",
        "')'",
        "','",
        "'='",
        "''''",
    ]

    symbolicNames = [
        "<INVALID>",
        "GLOBAL_WHITESPACE",
        "TAG_START",
        "CONTEXT_START",
        "CONTEXT_END",
        "TEXT",
        "ANY",
        "TAG_WHITESPACE",
        "ARGS_START",
        "TAG_ID",
        "ARGS_WHITESPACE",
        "ARG_END",
        "ARG_SEPARATOR",
        "NUMERIC_VALUE",
        "BOOLEAN_VALUE",
        "STRING_START",
        "ARG_NAME",
        "ARG_EQUALS",
        "STRING_VALUE",
        "STRING_END",
        "EMPTY_STRING",
    ]

    ruleNames = [
        "ID",
        "LETTER",
        "NUMBER_CHAR",
        "GLOBAL_WHITESPACE",
        "TAG_START",
        "CONTEXT_START",
        "CONTEXT_END",
        "TEXT",
        "ANY",
        "TAG_WHITESPACE",
        "ARGS_START",
        "TAG_ID",
        "ARGS_WHITESPACE",
        "ARG_END",
        "ARG_SEPARATOR",
        "NUMERIC_VALUE",
        "BOOLEAN_VALUE",
        "EMPTY_STRING",
        "STRING_START",
        "ARG_NAME",
        "ARG_EQUALS",
        "STRING_VALUE",
        "STRING_END",
    ]

    grammarFileName = "TagTemplateLexer.g4"

    def __init__(self, input=None, output: TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.8")
        self._interp = LexerATNSimulator(
            self, self.atn, self.decisionsToDFA, PredictionContextCache()
        )
        self._actions = None
        self._predicates = None
