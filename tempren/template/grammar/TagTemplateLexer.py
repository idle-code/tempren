# Generated from TagTemplateLexer.g4 by ANTLR 4.8
import sys
from io import StringIO
from typing.io import TextIO

from antlr4 import *


def serializedATN():
    with StringIO() as buf:
        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2\22")
        buf.write("{\b\1\b\1\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6")
        buf.write("\4\7\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r")
        buf.write("\t\r\4\16\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22")
        buf.write("\4\23\t\23\4\24\t\24\3\2\3\2\3\2\3\2\3\3\3\3\3\3\3\3\3")
        buf.write("\4\3\4\3\5\3\5\3\6\6\69\n\6\r\6\16\6:\3\7\3\7\3\b\3\b")
        buf.write("\3\b\3\b\3\t\3\t\3\n\3\n\3\n\3\n\3\13\3\13\3\f\6\fL\n")
        buf.write("\f\r\f\16\fM\3\r\3\r\3\r\3\r\3\r\3\r\3\r\3\r\3\r\5\rY")
        buf.write("\n\r\3\16\3\16\3\16\3\16\3\17\3\17\3\20\3\20\5\20c\n\20")
        buf.write("\3\20\3\20\3\20\7\20h\n\20\f\20\16\20k\13\20\3\21\3\21")
        buf.write("\3\22\3\22\3\23\3\23\3\23\6\23t\n\23\r\23\16\23u\3\24")
        buf.write("\3\24\3\24\3\24\2\2\25\5\3\7\4\t\5\13\6\r\7\17\b\21\t")
        buf.write("\23\n\25\13\27\f\31\r\33\16\35\17\37\20!\2#\2%\2'\21")
        buf.write(")\22\5\2\3\4\b\4\2\13\f\17\17\7\2\13\f\17\17''}}\177")
        buf.write('\177\5\2\13\f\17\17""\4\2C\\c|\3\2\62;\4\2))^^\2~\2')
        buf.write("\5\3\2\2\2\2\7\3\2\2\2\2\t\3\2\2\2\2\13\3\2\2\2\2\r\3")
        buf.write("\2\2\2\2\17\3\2\2\2\3\21\3\2\2\2\3\23\3\2\2\2\3\25\3\2")
        buf.write("\2\2\3\27\3\2\2\2\3\31\3\2\2\2\3\33\3\2\2\2\3\35\3\2\2")
        buf.write("\2\3\37\3\2\2\2\4'\3\2\2\2\4)\3\2\2\2\5+\3\2\2\2\7/\3")
        buf.write("\2\2\2\t\63\3\2\2\2\13\65\3\2\2\2\r8\3\2\2\2\17<\3\2\2")
        buf.write("\2\21>\3\2\2\2\23B\3\2\2\2\25D\3\2\2\2\27H\3\2\2\2\31")
        buf.write("K\3\2\2\2\33X\3\2\2\2\35Z\3\2\2\2\37^\3\2\2\2!b\3\2\2")
        buf.write("\2#l\3\2\2\2%n\3\2\2\2's\3\2\2\2)w\3\2\2\2+,\t\2\2\2")
        buf.write(",-\3\2\2\2-.\b\2\2\2.\6\3\2\2\2/\60\7'\2\2\60\61\3\2")
        buf.write("\2\2\61\62\b\3\3\2\62\b\3\2\2\2\63\64\7}\2\2\64\n\3\2")
        buf.write("\2\2\65\66\7\177\2\2\66\f\3\2\2\2\679\n\3\2\28\67\3\2")
        buf.write("\2\29:\3\2\2\2:8\3\2\2\2:;\3\2\2\2;\16\3\2\2\2<=\13\2")
        buf.write("\2\2=\20\3\2\2\2>?\t\4\2\2?@\3\2\2\2@A\b\b\2\2A\22\3\2")
        buf.write("\2\2BC\7*\2\2C\24\3\2\2\2DE\7+\2\2EF\3\2\2\2FG\b\n\4\2")
        buf.write("G\26\3\2\2\2HI\7.\2\2I\30\3\2\2\2JL\5%\22\2KJ\3\2\2\2")
        buf.write("LM\3\2\2\2MK\3\2\2\2MN\3\2\2\2N\32\3\2\2\2OP\7v\2\2PQ")
        buf.write("\7t\2\2QR\7w\2\2RY\7g\2\2ST\7h\2\2TU\7c\2\2UV\7n\2\2V")
        buf.write("W\7u\2\2WY\7g\2\2XO\3\2\2\2XS\3\2\2\2Y\34\3\2\2\2Z[\7")
        buf.write(")\2\2[\\\3\2\2\2\\]\b\16\5\2]\36\3\2\2\2^_\5!\20\2_ \3")
        buf.write("\2\2\2`c\5#\21\2ac\7a\2\2b`\3\2\2\2ba\3\2\2\2ci\3\2\2")
        buf.write("\2dh\5#\21\2eh\5%\22\2fh\7a\2\2gd\3\2\2\2ge\3\2\2\2gf")
        buf.write('\3\2\2\2hk\3\2\2\2ig\3\2\2\2ij\3\2\2\2j"\3\2\2\2ki\3')
        buf.write("\2\2\2lm\t\5\2\2m$\3\2\2\2no\t\6\2\2o&\3\2\2\2pt\n\7\2")
        buf.write("\2qr\7^\2\2rt\t\7\2\2sp\3\2\2\2sq\3\2\2\2tu\3\2\2\2us")
        buf.write("\3\2\2\2uv\3\2\2\2v(\3\2\2\2wx\7)\2\2xy\3\2\2\2yz\b\24")
        buf.write("\4\2z*\3\2\2\2\r\2\3\4:MXbgisu\6\b\2\2\7\3\2\6\2\2\7\4")
        buf.write("\2")
        return buf.getvalue()


class TagTemplateLexer(Lexer):

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [DFA(ds, i) for i, ds in enumerate(atn.decisionToState)]

    TAG_MODE = 1
    STRING_MODE = 2

    GLOBAL_WHITESPACE = 1
    TAG_START = 2
    CONTEXT_START = 3
    CONTEXT_END = 4
    TEXT = 5
    ANY = 6
    TAG_WHITESPACE = 7
    ARG_START = 8
    ARG_END = 9
    ARG_SEPARATOR = 10
    NUMERIC_VALUE = 11
    BOOLEAN_VALUE = 12
    STRING_START = 13
    TAG_ID = 14
    STRING_VALUE = 15
    STRING_END = 16

    channelNames = [u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN"]

    modeNames = ["DEFAULT_MODE", "TAG_MODE", "STRING_MODE"]

    literalNames = ["<INVALID>", "'%'", "'{'", "'}'", "'('", "')'", "','"]

    symbolicNames = [
        "<INVALID>",
        "GLOBAL_WHITESPACE",
        "TAG_START",
        "CONTEXT_START",
        "CONTEXT_END",
        "TEXT",
        "ANY",
        "TAG_WHITESPACE",
        "ARG_START",
        "ARG_END",
        "ARG_SEPARATOR",
        "NUMERIC_VALUE",
        "BOOLEAN_VALUE",
        "STRING_START",
        "TAG_ID",
        "STRING_VALUE",
        "STRING_END",
    ]

    ruleNames = [
        "GLOBAL_WHITESPACE",
        "TAG_START",
        "CONTEXT_START",
        "CONTEXT_END",
        "TEXT",
        "ANY",
        "TAG_WHITESPACE",
        "ARG_START",
        "ARG_END",
        "ARG_SEPARATOR",
        "NUMERIC_VALUE",
        "BOOLEAN_VALUE",
        "STRING_START",
        "TAG_ID",
        "ID",
        "LETTER",
        "NUMBER_CHAR",
        "STRING_VALUE",
        "STRING_END",
    ]

    grammarFileName = "TagTemplateLexer.g4"

    def __init__(self, input=None, output: TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.8")
        self._interp = LexerATNSimulator(
            self, self.atn, self.decisionsToDFA, PredictionContextCache()
        )
        self._actions = None
        self._predicates = None
